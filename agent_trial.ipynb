{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_fireworks.chat_models import ChatFireworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain.agents import create_tool_calling_agent, create_react_agent, AgentExecutor\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.globals import set_debug, set_verbose\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain import hub\n",
    "\n",
    "set_debug(False)\n",
    "set_verbose(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "News_api_key = os.environ[\"NEWS_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.0\n",
    "MAX_NEW_TOKENS = 1000\n",
    "\n",
    "MODELS = {\n",
    "    \"llama-v2-70b-chat\": ChatFireworks(\n",
    "        model_name=\"accounts/fireworks/models/llama-v2-70b-chat\",\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_NEW_TOKENS,            \n",
    "    ),\n",
    "    \"llama-v3-70b-instruct\": ChatFireworks(\n",
    "        model_name=\"accounts/fireworks/models/llama-v3-70b-instruct\",\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_NEW_TOKENS,            \n",
    "    ),    \n",
    "    \"firefunction\": ChatFireworks(\n",
    "        model_name=\"accounts/fireworks/models/firefunction-v1\",\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_NEW_TOKENS,            \n",
    "    ),\n",
    "    \"gpt3_5turbo\": ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_NEW_TOKENS,\n",
    "    ),    \n",
    "    \"gpt4o\": ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_NEW_TOKENS,\n",
    "    ),\n",
    "    \"mistral_large\": ChatMistralAI(\n",
    "        model=\"mistral-large-latest\",\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_NEW_TOKENS,\n",
    "    ),\n",
    "    \"gemini_flash\": ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-flash-latest\",\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_NEW_TOKENS,\n",
    "    ),\n",
    "    \"gemini_pro\": ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-pro\",\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_NEW_TOKENS,\n",
    "    ),\n",
    "}\n",
    "\n",
    "model_type = \"gemini_flash\"\n",
    "llm = MODELS[model_type]\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "llm_math_tool, weather_tool, news_tool, wikipedia_tool, arxiv_tool, websearch_tool = load_tools([\"llm-math\", \"open-meteo-api\", \"news-api\", \"wikipedia\", \"arxiv\", \"ddg-search\"], news_api_key=News_api_key, llm=llm)\n",
    "\n",
    "#llm_math_tool.invoke(\"What is the square root of 4?\")\n",
    "#wikipedia_tool.invoke(\"How many people live in Prague?\")\n",
    "#print(weather_tool.invoke(prompt, verbose=False))\n",
    "#print(news_tool.invoke(\"What are the 10 most important news in Prague? Answer in 10 bullet points\"))\n",
    "#print(arxiv_tool.invoke(\"List the title of 10 scientific papers about LLM agents published in this year.\", verbose=True))\n",
    "#print(websearch_tool.invoke(\"Who won the most Oscar in this year?\"))\n",
    "#print(pubmed_tool.invoke(\"List papers about Vortioxetin.\"))llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[llm_math_tool, arxiv_tool, news_tool, weather_tool, wikipedia_tool, websearch_tool] # More tools could be added\n",
    "\n",
    "if model_type.startswith(\"llama\"):\n",
    "    prompt_react = hub.pull(\"hwchase17/react\")\n",
    "    agent = create_react_agent(llm, tools, prompt_react)\n",
    "else:\n",
    "    prompt_tool_calling = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"{system_prompt}\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ])        \n",
    "    agent = create_tool_calling_agent(llm, tools, prompt_tool_calling)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose = True, stream_runnable=False)\n",
    "# , enable_automatic_function_calling=True\n",
    "\n",
    "agent_chain = agent_executor | itemgetter(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You're a helpful assistant. Always use tools to answer questions. Always use the Calculator for calculations, even when adding 2 numbers or calculating averages. The current date is {datetime.today().strftime('%Y-%m-%d')}\"\n",
    "\n",
    "#prompt = \"What is the square root of 2?\"\n",
    "#prompt = \"What is the weather like in Budapest?\"\n",
    "#prompt = \"What are the 10 trending news in Budapest Hungary? Answer in 10 bullet points.\"\n",
    "#prompt = \"How many people live in Budapest?\"\n",
    "#prompt = \"Who won the most Oscar in this year?\"\n",
    "#prompt = \"List the title of 10 scientific papers about LLM agents published in this year.\"\n",
    "\n",
    "#prompt = \"What are the maximum, minimum and average temperature values as well as the sum of precipitations on each of the coming 3 days in Budapest?\"\n",
    "#prompt = f\"Create a table that contains the date as well as the maximum, minimum and average temperature values as well as the sum of precipitations in the coming 7 days in Budapest\"\n",
    "prompt = f\"\"\"Create a table that contains the date as well as the maximum, minimum and average temperature values as well as the sum of precipitations separately for each of the coming 7 days in Budapest.\n",
    "Then include a line with each of the average of the maximum, minimum and average temperature values for these 7 days. And after all that also write a list with 10 current news in Budapest Hungary.\"\"\"\n",
    "\n",
    "prompt = \"What is the square root of 2?\"\n",
    "streaming = False\n",
    "\n",
    "response = \"\"\n",
    "if streaming == True:\n",
    "    for new_token in agent_chain.stream({\"system_prompt\": system_prompt, \"input\": prompt}):\n",
    "        print(new_token, end=\"\")\n",
    "        response = response + new_token\n",
    "else:\n",
    "    response = agent_chain.invoke({\"system_prompt\": system_prompt, \"input\": prompt})\n",
    "    print(response)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent_executor.invoke({\"input\": \"How many people live in Budapest and Prague together?\"})\n",
    "print(agent_chain.invoke({\"system_prompt\": system_prompt, \"input\": \"What is the square root of 2?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_chain.invoke({\"system_prompt\": system_prompt, \"input\": \"What is the weather like in Budapest?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(agent_chain.invoke({\"system_prompt\": system_prompt, \"input\": \"What are the 10 trending news in Budapest Hungary? Answer in 10 bullet points.\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_chain.invoke({\"system_prompt\": system_prompt, \"input\": \"How many people live in Budapest?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_chain.invoke({\"system_prompt\": system_prompt, \"input\": \"Who won the most Oscar in this year?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_chain.invoke({\"system_prompt\": system_prompt, \"input\": \"List the title of 10 scientific papers about LLM agents published in this year.\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_chain.invoke({\"system_prompt\": system_prompt, \"input\": \"What are the maximum, minimum and average temperature values as well as the sum of precipitations on each of the coming 3 days in Budapest?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_chain.invoke({\"system_prompt\": system_prompt, \"input\": \"Create a table that contains the date as well as the maximum, minimum and average temperature values as well as the sum of precipitations in the coming 7 days in Budapest?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_chain.invoke({\"system_prompt\": system_prompt, \"input\": \"\"\"Create a table that contains the date as well as the maximum, minimum and average temperature values as well as the sum of precipitations separately for each of the coming 7 days in Budapest.\n",
    "Then include a line with each of the average of the maximum, minimum and avarage temperature values for these 7 days. And after all that also write a list with 10 current news in Budapest Hungary.\"\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
